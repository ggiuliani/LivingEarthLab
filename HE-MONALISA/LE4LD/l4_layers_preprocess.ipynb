{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc136f29-f729-4557-997d-50de6d7571f7",
   "metadata": {},
   "source": [
    "# Living Earth for Land Degradation\n",
    "L4 layers pre-processing\n",
    "---\n",
    "\n",
    "This notebookprovides an interactive workflow to preprocess L4 layers, Environmental Descriptors (ED), for implementation of Living Earth for Land Degradation pipeline.\n",
    "\n",
    "\n",
    "Authors: Audrey Lambiel, Mona Bonnier, Carole Planque, Gregory Giuliani\n",
    "\n",
    "contact: audrey.lambiel@unige.ch\n",
    "\n",
    "----\n",
    "**Inputs**\n",
    "- Rules JSON : defines per-layer preprocessing.\n",
    "- AOI file : contains min_x, max_x, min_y, max_y (in degrees), resolution (meters), and crs (EPSG code).\n",
    "- Input folder: contains source rasters or vectors referenced by the rules JSON.\n",
    "- Output folder: destination for generated GeoTIFF files.\n",
    "\n",
    "**What it does**\n",
    "\n",
    "- *Setting up paths and parameters* (rules JSON, AOI file, input and output directories)\n",
    "- *Parsing the Area of Interest (AOI)* (extent, resolution, CRS)\n",
    "- *Applying preprocessing* per layer according to the JSON rules (see table hereafter)\n",
    "- *Visualizing outputs* with appropriate color maps for continuous and categorical data\n",
    "\n",
    "| input type       |preprocess       |description       |  output type   |\n",
    "|---     |---    |---    |---    |\n",
    "|  cat     |  None   |  No preprocess needed   | cat   |\n",
    "|  cat     |  reclassification |  Reclassified according to a dictionnary |cat    |\n",
    "|  con     |  None |  No preprocess needed   |con    |\n",
    "|  con     |  reclassification  |  Reclassified according to a dictionnary |cat    |\n",
    "|  con     |  formula  |  Apply a numpy formula, e.g. multiplied by a factor   |con    |\n",
    "|  con     |  focal  |  Apply a focal function, i.e. sum   |con    |\n",
    "\n",
    "\n",
    "**How it works**\n",
    "\n",
    "User should first read carefully the 'l4_layers_LE4LD_modified.py' and modifiy it if needed (e.g. change number of class, type of layer, categorical or continuous, ...). To do so, use **custom_l4_layers_LE4LD_modified.ipynb** notebook. \n",
    "\n",
    "Once this step is done, make sure that the rules file (sepcified under 'json_path') is up to date, or create it if needed. \n",
    "\n",
    "Then:\n",
    "- update the paths and parameters in the setup below\n",
    "- run the AOI parsing cell\n",
    "- run the processing cell to execture all layer rules\n",
    "- inspect the plots for each output to verify preprocess results\n",
    "\n",
    "**Requirements**\n",
    "\n",
    "Please ensure the following Python packages are installed in your environment:\n",
    "\n",
    "- `numpy`\n",
    "- `rasterio`\n",
    "- `geopandas`\n",
    "- `pyproj`\n",
    "- `matplotlib`\n",
    "- `earthpy`\n",
    "- `scipy`\n",
    "\n",
    "> If you use Conda, a typical environment might be created with:\n",
    "```bash\n",
    "conda create -n le4ld python=3.13.9 numpy rasterio geopandas pyproj matplotlib earthpy scipy\n",
    "conda activate le4ld\n",
    "```\n",
    "\n",
    "---\n",
    "## Set up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190a20ef-ec92-4ee0-90b8-22c815538e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules and libraries\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from pyproj import Transformer\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.features import rasterize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import earthpy.plot as ep\n",
    "from scipy.ndimage import convolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c240d3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = \"C:/monalisa/rules.json\"  # Update as needed\n",
    "aoi_path = \"C:/monalisa/aoi/Asterousia.txt\"  # Update as needed\n",
    "input_path = \"C:/monalisa/input_test\" # Update as needed\n",
    "output_path = \"C:/monalisa/l4_asterousia\"  # Update as needed\n",
    "nodata_val = 0\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66874c78-5ee4-4773-b0a7-13313b485a37",
   "metadata": {},
   "source": [
    "---\n",
    "## Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ddfba2-b85a-4c68-a26b-a8c289bb63f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom functions\n",
    "def parse_aoi(aoi_file):\n",
    "    \"\"\"\n",
    "    Parse AOI file to extract extent (in degrees), resolution (in meters), and CRS.\n",
    "    Then convert extent to meters using the target CRS.\n",
    "    \"\"\"\n",
    "    extent = {}\n",
    "    resolution = None\n",
    "    crs = None\n",
    "\n",
    "    try:\n",
    "        with open(aoi_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line.startswith(\"min_x\"): extent[\"min_x\"] = float(line.split(\":\")[1])\n",
    "                elif line.startswith(\"max_x\"): extent[\"max_x\"] = float(line.split(\":\")[1])\n",
    "                elif line.startswith(\"min_y\"): extent[\"min_y\"] = float(line.split(\":\")[1])\n",
    "                elif line.startswith(\"max_y\"): extent[\"max_y\"] = float(line.split(\":\")[1])\n",
    "                elif line.startswith(\"resolution\"):\n",
    "                    # Extract numbers inside brackets\n",
    "                    nums = re.findall(r\"[-]?\\d+\", line)\n",
    "                    resolution = [abs(float(n)) for n in nums]  # Ensure positive values\n",
    "                elif line.startswith(\"crs\"):\n",
    "                    match = re.search(r'EPSG:\\d+', line)\n",
    "                    if match:\n",
    "                        crs = match.group(0)\n",
    "\n",
    "        if not extent or not resolution or not crs:\n",
    "            raise ValueError(\"AOI file is missing required fields (extent, resolution, or CRS).\")\n",
    "\n",
    "        # Convert extent from degrees to meters using pyproj\n",
    "        transformer = Transformer.from_crs(\"EPSG:4326\", crs, always_xy=True)\n",
    "        min_x_m, min_y_m = transformer.transform(extent[\"min_x\"], extent[\"min_y\"])\n",
    "        max_x_m, max_y_m = transformer.transform(extent[\"max_x\"], extent[\"max_y\"])\n",
    "        extent_m = {\"min_x\": min_x_m, \"max_x\": max_x_m, \"min_y\": min_y_m, \"max_y\": max_y_m}\n",
    "\n",
    "        return extent_m, resolution, crs\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"AOI parsing failed: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "def process_cat_reclass(layer_name, rule, preprocess, nodata_val, layer_path, output_path):\n",
    "    \"\"\"\n",
    "    Reclassify categorical raster according to JSON rules.\n",
    "    \"\"\"\n",
    "    original_classes = {int(k): v for k, v in rule[\"original_classes\"].items()}\n",
    "    reclass_dict = rule[\"reclass_dict\"]\n",
    "    out_path = f\"{output_path}/{layer_name}.tif\"\n",
    "\n",
    "    with rasterio.open(layer_path) as src:\n",
    "        band = src.read(1)\n",
    "        if src.nodata is not None:\n",
    "            band[band == src.nodata] = nodata_val\n",
    "\n",
    "        reclass_array = np.full(band.shape, nodata_val, dtype=object)\n",
    "        value_to_new = {val: reclass_dict.get(name, nodata_val) for val, name in original_classes.items()}\n",
    "\n",
    "        for val in np.unique(band[~np.isnan(band)]):\n",
    "            reclass_array[band == val] = value_to_new.get(int(val), nodata_val)\n",
    "\n",
    "        flat_values = reclass_array.flatten()\n",
    "        present_classes = sorted(set(val for val in flat_values if isinstance(val, str)))\n",
    "        new_class_codes = {cls: int(cls[1:]) for cls in present_classes}\n",
    "\n",
    "        reclass_int = np.zeros_like(band, dtype=\"int16\")\n",
    "        for cls, code in new_class_codes.items():\n",
    "            reclass_int[reclass_array == cls] = code\n",
    "\n",
    "        meta = src.meta.copy()\n",
    "        meta.update({\"dtype\": \"int16\", \"count\": 1, \"nodata\": nodata_val})\n",
    "\n",
    "        with rasterio.open(out_path, \"w\", **meta) as dst:\n",
    "            dst.write(reclass_int, 1)\n",
    "\n",
    "    print(f\"{layer_name} processed ({preprocess}) and exported.\")\n",
    "    return out_path\n",
    "\n",
    "\n",
    "def process_con_reclass(layer_name, rule, preprocess, nodata_val, layer_path, output_path):\n",
    "    \"\"\"\n",
    "    Reclassify continuous raster according to JSON rules.\n",
    "    \"\"\"\n",
    "    rules_list = rule[\"reclass_rules\"]\n",
    "    out_path = f\"{output_path}/{layer_name}.tif\"\n",
    "\n",
    "    with rasterio.open(layer_path) as src:\n",
    "        data = src.read(1)\n",
    "        if src.nodata is not None:\n",
    "            data[data == src.nodata] = nodata_val\n",
    "\n",
    "        reclass_array = np.full(data.shape, nodata_val, dtype=object)\n",
    "        for rule_entry in rules_list:\n",
    "            cls = rule_entry[\"class\"]\n",
    "            low, high = rule_entry[\"min\"], rule_entry[\"max\"]\n",
    "            if low == \"None\" and high != \"None\":\n",
    "                mask = data <= high\n",
    "            elif high == \"None\" and low != \"None\":\n",
    "                mask = data >= low\n",
    "            elif low != \"None\" and high != \"None\":\n",
    "                mask = (data >= low) & (data <= high)\n",
    "            else:\n",
    "                mask = np.full(data.shape, False)\n",
    "            reclass_array[mask] = cls\n",
    "\n",
    "        flat_values = reclass_array.flatten()\n",
    "        present_classes = sorted(set(val for val in flat_values if isinstance(val, str)))\n",
    "        new_class_codes = {cls: int(cls[1:]) for cls in present_classes}\n",
    "\n",
    "        reclass_int = np.zeros_like(data, dtype=\"int16\")\n",
    "        for cls, code in new_class_codes.items():\n",
    "            reclass_int[reclass_array == cls] = code\n",
    "\n",
    "        meta = src.meta.copy()\n",
    "        meta.update(dtype=\"int16\", nodata=nodata_val)\n",
    "\n",
    "        with rasterio.open(out_path, \"w\", **meta) as dst:\n",
    "            dst.write(reclass_int, 1)\n",
    "\n",
    "    print(f\"{layer_name} processed ({preprocess}) and exported.\")\n",
    "    return out_path\n",
    "\n",
    "\n",
    "def process_con_formula(layer_name, rule, preprocess, nodata_val, layer_path, output_path):\n",
    "    \"\"\"\n",
    "    Apply numpy formula defined in JSON to a continuous raster.\n",
    "    \"\"\"\n",
    "    expression = rule.get(\"expression\")\n",
    "    if not expression:\n",
    "        print(f\"{layer_name} has no formula expression, skipped.\")\n",
    "        return None\n",
    "\n",
    "    out_path = f\"{output_path}/{layer_name}.tif\"\n",
    "    with rasterio.open(layer_path) as src:\n",
    "        data = src.read(1).astype(float)\n",
    "        result = eval(expression, {\"np\": np, \"data\": data})\n",
    "\n",
    "        meta = src.meta.copy()\n",
    "        meta.update(dtype=\"float32\")\n",
    "\n",
    "        with rasterio.open(out_path, \"w\", **meta) as dst:\n",
    "            dst.write(result.astype(\"float32\"), 1)\n",
    "\n",
    "    print(f\"{layer_name} processed ({preprocess}) and exported.\")\n",
    "    return out_path\n",
    "\n",
    "\n",
    "def process_con_focal(layer_name, rule, preprocess, nodata_val, layer_path, output_path):\n",
    "    \"\"\"\n",
    "    Apply focal statistics to compute sum within a moving window.\n",
    "    \"\"\"\n",
    "    resolution = rule.get(\"resolution_m\")\n",
    "    window_area = rule.get(\"window_m2\")\n",
    "    side_length = np.sqrt(window_area)\n",
    "    window_size = int(np.round(side_length / resolution))\n",
    "\n",
    "    out_path = f\"{output_path}/{layer_name}.tif\"\n",
    "    with rasterio.open(layer_path) as src:\n",
    "        data = src.read(1).astype(float)\n",
    "        if src.nodata is not None:\n",
    "            data[data == src.nodata] = 0\n",
    "\n",
    "        kernel = np.ones((window_size, window_size), dtype=float)\n",
    "        result = convolve(data, kernel, mode=\"constant\", cval=0.0)\n",
    "\n",
    "        meta = src.meta.copy()\n",
    "        meta.update(dtype=\"float32\", nodata=nodata_val)\n",
    "\n",
    "        with rasterio.open(out_path, \"w\", **meta) as dst:\n",
    "            dst.write(result.astype(\"float32\"), 1)\n",
    "\n",
    "    print(f\"{layer_name} processed ({preprocess}, window={window_area} m²) and exported.\")\n",
    "    return out_path\n",
    "\n",
    "\n",
    "def process_vector_con_focal(layer_name, rule, preprocess, nodata_val, layer_path, output_path, extent, resolution, crs):\n",
    "    \"\"\"\n",
    "    Rasterize vector data (points or lines) and compute density using focal statistics.\n",
    "    extent: dict with min_x, max_x, min_y, max_y\n",
    "    resolution: [pixel_size_x, pixel_size_y]\n",
    "    \"\"\"\n",
    "    resolution_x, resolution_y = resolution\n",
    "    width = int((extent[\"max_x\"] - extent[\"min_x\"]) / abs(resolution_x))\n",
    "    height = int((extent[\"max_y\"] - extent[\"min_y\"]) / abs(resolution_y))\n",
    "    transform = from_origin(extent[\"min_x\"], extent[\"max_y\"], abs(resolution_x), abs(resolution_y))\n",
    "\n",
    "    # Read vector data\n",
    "    gdf = gpd.read_file(layer_path).to_crs(crs)\n",
    "\n",
    "    # Prepare shapes for rasterization\n",
    "    if gdf.geometry.iloc[0].geom_type == \"Point\":\n",
    "        # Each point contributes 1\n",
    "        shapes = ((geom, 1) for geom in gdf.geometry)\n",
    "    elif gdf.geometry.iloc[0].geom_type in [\"LineString\", \"MultiLineString\"]:\n",
    "        # Each line contributes its length in meters\n",
    "        shapes = ((geom, geom.length) for geom in gdf.geometry)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported geometry type for focal density.\")\n",
    "        \n",
    "    if width <= 0 or height <= 0:\n",
    "        raise ValueError(f\"Invalid grid size: width={width}, height={height}. Check AOI extent and resolution.\")\n",
    "\n",
    "    # Rasterize: initial grid with counts or lengths\n",
    "    base_raster = rasterize(\n",
    "        shapes=shapes,\n",
    "        out_shape=(height, width),\n",
    "        transform=transform,\n",
    "        fill=0,\n",
    "        dtype=\"float32\"\n",
    "    )\n",
    "\n",
    "    # Apply focal statistics for density\n",
    "    window_area = rule.get(\"window_m2\")\n",
    "    side_length = np.sqrt(window_area)\n",
    "    window_size = int(np.round(side_length / abs(resolution_x)))\n",
    "    kernel = np.ones((window_size, window_size), dtype=float)\n",
    "    result = convolve(base_raster, kernel, mode=\"constant\", cval=0.0)\n",
    "\n",
    "    # Convert to density per m2\n",
    "    result = result / window_area\n",
    "\n",
    "    # Save raster\n",
    "    out_path = f\"{output_path}/{layer_name}.tif\"\n",
    "    meta = {\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"height\": height,\n",
    "        \"width\": width,\n",
    "        \"count\": 1,\n",
    "        \"dtype\": \"float32\",\n",
    "        \"crs\": crs,\n",
    "        \"transform\": transform,\n",
    "        \"nodata\": nodata_val\n",
    "    }\n",
    "    with rasterio.open(out_path, \"w\", **meta) as dst:\n",
    "        dst.write(result.astype(\"float32\"), 1)\n",
    "\n",
    "    print(f\"{layer_name} processed (vector focal density, window={window_area} m²) and exported.\")\n",
    "    return out_path\n",
    "\n",
    "\n",
    "def plot_raster(raster_path, ltype):\n",
    "    \"\"\"\n",
    "    Plot continous raster with a continuous colormap (viridis)\n",
    "    Plot categorical raster with categorical colormap (RdYlGn_r)\n",
    "    \"\"\"\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        data = src.read(1)\n",
    "\n",
    "    unique_values = sorted(set(data.flatten()))\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "\n",
    "    if ltype ==\"con\":\n",
    "        cmap = \"viridis\"\n",
    "        plt.imshow(data, cmap=cmap)\n",
    "        plt.colorbar(label=\"value\")\n",
    "        plt.title(f\"{os.path.basename(raster_path)}\", fontsize = 14)\n",
    "\n",
    "    elif ltype==\"cat\":\n",
    "        # create a normalized coloramp for LDDSI classes (from D100 to D200)\n",
    "        classes = [f\"D{v}\" for v in range(100, 201, 1)]\n",
    "        classes = [\"0\"] + classes\n",
    "        palette = plt.colormaps[\"RdYlGn_r\"]\n",
    "        palette = palette(np.linspace(0, 1, len(classes) - 1))\n",
    "        colors_list = [np.array([0, 0, 0, 1])] + list(palette)  # 0 = black\n",
    "        cmap = colors.ListedColormap(colors_list, name=\"lddsi_colors\")\n",
    "        classes_to_value = {cls: int(cls[1:]) for cls in classes if cls != \"0\"}\n",
    "        classes_to_value[\"0\"] = 0\n",
    "        bounds = sorted(classes_to_value.values())\n",
    "        norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "        class_names_list = [str(v) for v in unique_values]\n",
    "        \n",
    "        img = plt.imshow(data, cmap=cmap, norm=norm)\n",
    "        ep.draw_legend(img, titles=class_names_list)\n",
    "        plt.title(f\"{os.path.basename(raster_path)}\", fontsize=14)\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6818f9-86eb-4ac4-b0b1-cfc475b5d352",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Parse AOI file\n",
    "extent, resolution, crs = parse_aoi(aoi_path)\n",
    "if extent is None or resolution is None or crs is None:\n",
    "    raise ValueError(\"Failed to parse AOI file. Check its format.\")\n",
    "\n",
    "# Main process\n",
    "try:\n",
    "    with open(json_path, \"r\") as f:\n",
    "        rules = json.load(f)\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load JSON rules: {e}\")\n",
    "    rules = {}\n",
    "\n",
    "for layer_name, rule in rules.items():\n",
    "    preprocess = rule.get(\"preprocess\", \"None\")\n",
    "    ltype = rule.get(\"type\")\n",
    "    layer_path = f\"{input_path}/{rule.get(\"filename_with_ext\")}\"\n",
    "\n",
    "    if not os.path.exists(layer_path):\n",
    "        print(f\"Layer path not found: {layer_path}\")\n",
    "        continue\n",
    "\n",
    "    if preprocess == \"None\":\n",
    "        out_path = f\"{output_path}/{layer_name}.tif\"\n",
    "        with rasterio.open(layer_path) as src:\n",
    "            data = src.read(1)\n",
    "            meta = src.meta.copy()\n",
    "            if src.nodata is not None:\n",
    "                data[data == src.nodata] = nodata_val\n",
    "            meta.update({\"nodata\": nodata_val})\n",
    "            with rasterio.open(out_path, \"w\", **meta) as dst:\n",
    "                dst.write(data, 1)\n",
    "        print(f\"{layer_name} skipped (no preprocessing) but exported.\")\n",
    "        plot_raster(out_path, ltype)\n",
    "        continue\n",
    "\n",
    "    if ltype == \"cat\" and preprocess == \"reclassification\":\n",
    "        path = process_cat_reclass(layer_name, rule, preprocess, nodata_val, layer_path, output_path)\n",
    "        plot_raster(path, ltype=\"cat\")\n",
    "    elif ltype == \"con\" and preprocess == \"reclassification\":\n",
    "        path = process_con_reclass(layer_name, rule, preprocess, nodata_val, layer_path, output_path)\n",
    "        plot_raster(path, ltype=\"con\")\n",
    "    elif ltype == \"con\" and preprocess == \"formula\":\n",
    "        path = process_con_formula(layer_name, rule, preprocess, nodata_val, layer_path, output_path)\n",
    "        if path: plot_raster(path, ltype=\"con\")\n",
    "    elif ltype == \"con\" and preprocess == \"focal\":\n",
    "        if layer_path.endswith(\".shp\"):\n",
    "            # Vector focal density\n",
    "            path = process_vector_con_focal(layer_name, rule, preprocess, nodata_val, layer_path, output_path, extent, resolution, crs)\n",
    "        else:\n",
    "            # Raster focal\n",
    "            path = process_con_focal(layer_name, rule, preprocess, nodata_val, layer_path, output_path)\n",
    "        plot_raster(path, ltype=\"con\")\n",
    "    else:\n",
    "        print(f\"{layer_name}: Unknown combination type={ltype}, preprocess={preprocess}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "le4ld",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

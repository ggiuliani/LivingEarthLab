{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1483e7f1",
   "metadata": {},
   "source": [
    "# Living Earth for Land Degradation\n",
    "L4 class Editor: UI + Black Formatting + File Generation\n",
    "---\n",
    "\n",
    "This notebook provides an interactive way to inspect, edit, and regenerate selected Level‑4 classification classes in the 'l4_layers_LE4LD_modified.py' source file used in the implementation of LE4LD in Living Earth pipeline.\n",
    "\n",
    "Authors: Audrey Lambiel, Mona Bonnier, Carole Planque, Gregory Giuliani\n",
    "\n",
    "Contact: audrey.lambiel@unige.ch\n",
    "\n",
    "---- \n",
    "**What it does**\n",
    "\n",
    "Parses the source file into an AST to safely read class blocks, docstrings, and __init__ bodies.\n",
    "Presents a UI (ipywidgets) where user select a class, edit per‑level output codes/descriptions and optional class boundaries, and adjust the base type (categorical vs continuous).\n",
    "Generates a new class block using programmatic edits.\n",
    "Uses Black formatting to ensure consistent, PEP8‑style code formatting:\n",
    "\n",
    "Preview formatting via a temporary scaffold so Black can format even if the fragment would otherwise fail to parse.\n",
    "Final Apply formatting of the entire file for uniform results.\n",
    "\n",
    "**How it works**\n",
    "\n",
    "The notebook reads the source file (SOURCE) into memory and builds a classes dict with metadata (name, base class, docstring, __init__ body, spans for replacement).\n",
    "UI widgets let you enter/modify output codes and class boundaries at specific levels.\n",
    "When you click Preview, the notebook constructs the updated class fragment and formats it with Black using a scaffold; when you click Apply, it splices the formatted block into the working text and then formats the entire file with Black before writing to OUTPUT.\n",
    "Class metadata is rebuilt after Apply/Reset so previews always reflect current contents.\n",
    "\n",
    "**Requirements**\n",
    "\n",
    "Python: 3.9+ (Black’s library API and ast.unparse are available from 3.9).\n",
    "Environment: Use a dedicated virtual environment (e.g., venv, Conda, ...) to keep dependencies isolated.\n",
    "\n",
    "Please ensure the following Python packages are installed in your environment:\n",
    "- `black`\n",
    "- `ipywidgets`\n",
    "- `ipykernel`\n",
    "\n",
    "+ standard library (ast, re, textwrape, shutil, ...)\n",
    "\n",
    "> If you use Conda, a typical environment might be created with:\n",
    "```bash\n",
    "conda create -n le4ld python=3.13.9 black ipywidgets ipykernel\n",
    "conda activate le4ld\n",
    "```\n",
    "\n",
    "**Safety and backups**\n",
    "\n",
    "The notebook creates a backup (SOURCE.bak) the first time you click on Apply and Write button. You can revert by replacing SOURCE with SOURCE.bak if needed. \n",
    "\n",
    "---\n",
    "\n",
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4ecd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules\n",
    "import re\n",
    "import ast\n",
    "import shutil\n",
    "from collections import OrderedDict\n",
    "import textwrap\n",
    "import black\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# config\n",
    "SOURCE = \"C:/monalisa/l4_layers_LE4LD_test.py\" # update as needed\n",
    "OUTPUT = \"C:/monalisa/l4_layers_LE4LD_custom.py\" # update as needed\n",
    "\n",
    "LEVEL_KEYS = list(range(100, 200, 5)) + [200] # define possible land degradation categories, per default 100-200 in steps of 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc45811e",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514fff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Black helper + pretty‑printers\n",
    "def format_with_black(source: str, line_length: int = 88) -> str:\n",
    "    \"\"\"\n",
    "    Return the Black-formatted version of `source`.\n",
    "    \"\"\"\n",
    "    mode = black.Mode(line_length=line_length)\n",
    "    return black.format_str(source, mode=mode)\n",
    "\n",
    "def _ordered_dict(d):\n",
    "    \"\"\"\n",
    "    Return OrderedDict sorted by key ascending (stable output).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return OrderedDict(sorted(d.items(), key=lambda kv: kv[0]))\n",
    "    except Exception:\n",
    "        return OrderedDict(d.items())\n",
    "\n",
    "def quote_str(s):\n",
    "    \"\"\"\n",
    "    Return a Python-literal quoted string (safe repr).\n",
    "    \"\"\"\n",
    "    return repr(str(s))\n",
    "\n",
    "def format_output_codes_literal(d, indent=\"    \"):\n",
    "    \"\"\"\n",
    "    Format { code: (\"label\", \"desc\"), ... } as a multi-line Python dict literal.\n",
    "    \"\"\"\n",
    "    if not d:\n",
    "        return \"{ }\"\n",
    "    od = _ordered_dict(d)\n",
    "    lines = [\"{\"]\n",
    "    for k, (label, desc) in od.items():\n",
    "        lines.append(f'{indent}{k} : ({quote_str(label)}, {quote_str(desc)}),')\n",
    "    lines[-1] = lines[-1].rstrip(\",\")\n",
    "    lines.append(\"}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def format_boundaries_literal(d, indent=\"    \"):\n",
    "    \"\"\"\n",
    "    Format { code: (min, max), ... } with None or numbers, multi-line.\n",
    "    \"\"\"\n",
    "    if not d:\n",
    "        return \"{ }\"\n",
    "    od = _ordered_dict(d)\n",
    "\n",
    "    def val_repr(x):\n",
    "        return \"None\" if x is None or x == \"\" else str(x)\n",
    "\n",
    "    lines = [\"{\"]\n",
    "    for k, (mn, mx) in od.items():\n",
    "        lines.append(f\"{indent}{k} : ({val_repr(mn)}, {val_repr(mx)}),\")\n",
    "    lines[-1] = lines[-1].rstrip(\",\")\n",
    "    lines.append(\"}\")\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deb32d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read source file\n",
    "with open(SOURCE, \"r\", encoding=\"utf-8\") as f:\n",
    "    source_text = f.read()\n",
    "\n",
    "# Build fast line->offset mapping for absolute slicing\n",
    "_lines = source_text.splitlines(keepends=True)\n",
    "_line_starts = []\n",
    "offset = 0\n",
    "for ln in _lines:\n",
    "    _line_starts.append(offset)\n",
    "    offset += len(ln)\n",
    "\n",
    "# AST facilities\n",
    "def span_to_slice(lineno, col, end_lineno, end_col):\n",
    "    \"\"\"\n",
    "    Convert a (lineno, col) .. (end_lineno, end_col) span to absolute (start, end) offsets.\n",
    "    \"\"\"\n",
    "    start = _line_starts[lineno - 1] + col\n",
    "    end = _line_starts[end_lineno - 1] + end_col\n",
    "    return start, end\n",
    "\n",
    "def get_source_segment_by_span(node):\n",
    "    \"\"\"\n",
    "    Return exact source text for an AST 'node' if span attributes are present.\n",
    "    \"\"\"\n",
    "    if not hasattr(node, \"lineno\") or not hasattr(node, \"end_lineno\"):\n",
    "        return \"\"\n",
    "    s, e = span_to_slice(node.lineno, node.col_offset, node.end_lineno, node.end_col_offset)\n",
    "    return source_text[s:e]\n",
    "\n",
    "module = ast.parse(source_text)\n",
    "\n",
    "def unparse_expr(expr):\n",
    "    \"\"\"\n",
    "    Best-effort conversion from AST expression to a string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return ast.unparse(expr)  # Python 3.9+\n",
    "    except Exception:\n",
    "        if isinstance(expr, ast.Name):\n",
    "            return expr.id\n",
    "        elif isinstance(expr, ast.Attribute):\n",
    "            return f\"{unparse_expr(expr.value)}.{expr.attr}\"\n",
    "        else:\n",
    "            return \"<expr>\"\n",
    "\n",
    "def get_base_class_string(cls: ast.ClassDef):\n",
    "    bases = [unparse_expr(b) for b in cls.bases]\n",
    "    return \", \".join(bases) if bases else \"\"\n",
    "\n",
    "def get_class_docstring_block(cls: ast.ClassDef):\n",
    "    \"\"\"Return the exact docstring block (including quotes) if present.\"\"\"\n",
    "    if not cls.body:\n",
    "        return \"\"\n",
    "    first = cls.body[0]\n",
    "    if isinstance(first, ast.Expr) and isinstance(first.value, ast.Constant) and isinstance(first.value.value, str):\n",
    "        return get_source_segment_by_span(first)\n",
    "    return \"\"\n",
    "\n",
    "def find_init_func(cls: ast.ClassDef):\n",
    "    for n in cls.body:\n",
    "        if isinstance(n, ast.FunctionDef) and n.name == \"__init__\":\n",
    "            return n\n",
    "    return None\n",
    "\n",
    "def get_init_body_text(init_func: ast.FunctionDef):\n",
    "    \"\"\"Return the body text of __init__ (without the header line).\"\"\"\n",
    "    full = get_source_segment_by_span(init_func)\n",
    "    newline_idx = full.find(\"\\n\")\n",
    "    if newline_idx == -1:\n",
    "        return \"\"\n",
    "    return full[newline_idx + 1 :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad57fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build classes metadata\n",
    "def build_classes_from_text(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parse 'text' to AST and rebuild the 'classes' metadata dict.\n",
    "    \"\"\"\n",
    "    module_local = ast.parse(text)\n",
    "    classes_local = {}\n",
    "\n",
    "    lines_local = text.splitlines(keepends=True)\n",
    "    line_starts_local = []\n",
    "    off = 0\n",
    "    for ln in lines_local:\n",
    "        line_starts_local.append(off)\n",
    "        off += len(ln)\n",
    "\n",
    "    def span_to_slice_local(lineno, col, end_lineno, end_col):\n",
    "        start = line_starts_local[lineno - 1] + col\n",
    "        end = line_starts_local[end_lineno - 1] + end_col\n",
    "        return start, end\n",
    "\n",
    "    def get_source_segment_by_span_local(node):\n",
    "        if not hasattr(node, \"lineno\") or not hasattr(node, \"end_lineno\"):\n",
    "            return \"\"\n",
    "        s, e = span_to_slice_local(node.lineno, node.col_offset, node.end_lineno, node.end_col_offset)\n",
    "        return text[s:e]\n",
    "\n",
    "    def get_class_docstring_block_local(cls: ast.ClassDef):\n",
    "        if not cls.body:\n",
    "            return \"\"\n",
    "        first = cls.body[0]\n",
    "        if isinstance(first, ast.Expr) and isinstance(first.value, ast.Constant) and isinstance(first.value.value, str):\n",
    "            return get_source_segment_by_span_local(first)\n",
    "        return \"\"\n",
    "\n",
    "    def find_init_func_local(cls: ast.ClassDef):\n",
    "        for n in cls.body:\n",
    "            if isinstance(n, ast.FunctionDef) and n.name == \"__init__\":\n",
    "                return n\n",
    "        return None\n",
    "\n",
    "    def get_init_body_text_local(init_func: ast.FunctionDef):\n",
    "        full = get_source_segment_by_span_local(init_func)\n",
    "        newline_idx = full.find(\"\\n\")\n",
    "        if newline_idx == -1:\n",
    "            return \"\"\n",
    "        return full[newline_idx + 1 :]\n",
    "\n",
    "    def unparse_expr_local(expr):\n",
    "        try:\n",
    "            return ast.unparse(expr)\n",
    "        except Exception:\n",
    "            if isinstance(expr, ast.Name):\n",
    "                return expr.id\n",
    "            elif isinstance(expr, ast.Attribute):\n",
    "                return f\"{unparse_expr_local(expr.value)}.{expr.attr}\"\n",
    "            else:\n",
    "                return \"<expr>\"\n",
    "\n",
    "    def get_base_class_string_local(cls: ast.ClassDef):\n",
    "        bases = [unparse_expr_local(b) for b in cls.bases]\n",
    "        return \", \".join(bases) if bases else \"\"\n",
    "\n",
    "    for node in module_local.body:\n",
    "        if isinstance(node, ast.ClassDef):\n",
    "            class_name = node.name\n",
    "            base_class = get_base_class_string_local(node)\n",
    "            doc_block = get_class_docstring_block_local(node)\n",
    "            init_func = find_init_func_local(node)\n",
    "            if not init_func:\n",
    "                continue\n",
    "            full_block = get_source_segment_by_span_local(node)\n",
    "            init_body = get_init_body_text_local(init_func)\n",
    "\n",
    "            input_layer_name_match = re.search(r'self\\.input_layer_name\\s*=\\s*\"([^\"]+)\"', init_body)\n",
    "            output_layer_name_match = re.search(r'self\\.output_layer_name\\s*=\\s*\"([^\"]+)\"', init_body)\n",
    "            layer_type_match = re.search(r'self\\.layer_type\\s*=\\s*([^\\n]+)', init_body)\n",
    "            output_codes_match = re.search(r'self\\.output_codes_descriptions\\s*=\\s*(\\{.*?\\})', init_body, re.DOTALL)\n",
    "            boundaries_match = re.search(r'self\\.class_boundaries\\s*=\\s*(\\{.*?\\})', init_body, re.DOTALL)\n",
    "\n",
    "            classes_local[class_name] = {\n",
    "                \"full_block\": full_block,\n",
    "                \"match_span\": span_to_slice_local(node.lineno, node.col_offset, node.end_lineno, node.end_col_offset),\n",
    "                \"class_name\": class_name,\n",
    "                \"base_class\": base_class,\n",
    "                \"docstring\": doc_block,\n",
    "                \"init_body\": init_body,\n",
    "                \"input_layer_name\": input_layer_name_match.group(1) if input_layer_name_match else \"\",\n",
    "                \"output_layer_name\": output_layer_name_match.group(1) if output_layer_name_match else \"\",\n",
    "                \"layer_type\": layer_type_match.group(1).strip() if layer_type_match else \"\",\n",
    "                \"output_codes_descriptions\": output_codes_match.group(1) if output_codes_match else \"\",\n",
    "                \"class_boundaries\": boundaries_match.group(1) if boundaries_match else \"\",\n",
    "            }\n",
    "\n",
    "    if not classes_local:\n",
    "        raise RuntimeError(\"No class with __init__ found while rebuilding classes.\")\n",
    "    return classes_local\n",
    "\n",
    "\n",
    "# Extract classes once\n",
    "classes = build_classes_from_text(source_text)\n",
    "working_text = source_text\n",
    "modification_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1704c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indentation helper\n",
    "def detect_class_inner_indent(full_class_block: str) -> str:\n",
    "    \"\"\"\n",
    "    Detect the indentation used inside the class by looking for its __init__ definition line.\n",
    "    Returns whitespace (tabs or spaces) used before 'def __init__'.\n",
    "    If not found, fall back to 4 spaces.\n",
    "    \"\"\"\n",
    "    for line in full_class_block.splitlines():\n",
    "        m = re.match(r\"^([ \\t]*)def\\s+__init__\\s*\\(\", line)\n",
    "        if m:\n",
    "            return m.group(1)\n",
    "    return \"    \"\n",
    "\n",
    "def indent_one_level(body: str, anchor_line: str) -> str:\n",
    "    \"\"\"\n",
    "    Indent `body` one level deeper than the leading whitespace on `anchor_line`.\n",
    "    Works for tabs or spaces; avoids hardcoded 4/8.\n",
    "    \"\"\"\n",
    "    m = re.match(r\"^([ \\t]*)\", anchor_line)\n",
    "    base_ws = m.group(1) if m else \"\"\n",
    "\n",
    "    if base_ws and set(base_ws) == {\"\\t\"}:\n",
    "        extra_ws = \"\\t\"\n",
    "    elif base_ws and set(base_ws) == {\" \"}:\n",
    "        extra_ws = base_ws  # same width as existing level (one more level)\n",
    "    else:\n",
    "        extra_ws = \" \"  # fallback: single space\n",
    "\n",
    "    normalized = textwrap.dedent(body.replace(\"\\t\", \"    \")).strip() + \"\\n\"\n",
    "    return textwrap.indent(normalized, base_ws + extra_ws)\n",
    "\n",
    "def black_format_block_with_scaffold(class_name: str, base: str, doc_raw: str, def_line: str, body_raw: str, class_inner_ws: str) -> str:\n",
    "    \"\"\"\n",
    "    Build a minimal valid class block, run Black, and return the formatted block.\n",
    "    The 'scaffold' is simply the class header + doc + def + body with consistent indents.\n",
    "    \"\"\"\n",
    "    doc_norm = textwrap.dedent(doc_raw).strip() + \"\\n\"\n",
    "    doc_indented = textwrap.indent(doc_norm, class_inner_ws)\n",
    "    body_indented = indent_one_level(body_raw, def_line)\n",
    "\n",
    "    temp_src = f\"class {class_name}({base}):\\n\" + doc_indented + def_line + body_indented\n",
    "    mode = black.Mode(line_length=88)\n",
    "    return black.format_str(temp_src, mode=mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eb4903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI widgets\n",
    "class_selector = widgets.Dropdown(\n",
    "    options=sorted(list(classes.keys())),\n",
    "    description=\"Class :\",\n",
    "    layout=widgets.Layout(width=\"60%\"),\n",
    ")\n",
    "\n",
    "base_options = [\n",
    "    \"l4_base.Level4ClassificationCatergoricalLayer\",  # keep original spelling for compatibility\n",
    "    \"l4_base.Level4ClassificationContinuousLayer\",\n",
    "]\n",
    "base_selector = widgets.Dropdown(\n",
    "    options=base_options,\n",
    "    description=\"Base type :\",\n",
    "    layout=widgets.Layout(width=\"60%\"),\n",
    ")\n",
    "\n",
    "docstring_widget = widgets.Textarea(\n",
    "    description=\"docstring:\",\n",
    "    layout=widgets.Layout(width=\"100%\", height=\"150px\"),\n",
    ")\n",
    "\n",
    "code_widgets = {}\n",
    "desc_widgets = {}\n",
    "out_rows = []\n",
    "for k in LEVEL_KEYS:\n",
    "    code_widgets[k] = widgets.Text(value=\"\", placeholder=f\"D{k}\", layout=widgets.Layout(width=\"120px\"))\n",
    "    desc_widgets[k] = widgets.Text(value=\"\", placeholder=\"description\", layout=widgets.Layout(width=\"60%\"))\n",
    "    out_rows.append(widgets.HBox([widgets.Label(f\"{k} :\"), code_widgets[k], desc_widgets[k]]))\n",
    "output_codes_box = widgets.VBox(out_rows)\n",
    "\n",
    "min_widgets = {}\n",
    "max_widgets = {}\n",
    "bnd_rows = []\n",
    "for k in LEVEL_KEYS:\n",
    "    min_widgets[k] = widgets.Text(value=\"\", placeholder=\"min or None\", layout=widgets.Layout(width=\"140px\"))\n",
    "    max_widgets[k] = widgets.Text(value=\"\", placeholder=\"max or None\", layout=widgets.Layout(width=\"140px\"))\n",
    "    bnd_rows.append(widgets.HBox([widgets.Label(f\"{k} :\"), min_widgets[k], max_widgets[k]]))\n",
    "boundaries_box = widgets.VBox(bnd_rows)\n",
    "\n",
    "advanced_box = widgets.Accordion(children=[output_codes_box, boundaries_box])\n",
    "advanced_box.set_title(0, \"Output codes (per level)\")\n",
    "advanced_box.set_title(1, \"Class boundaries (per level)\")\n",
    "\n",
    "apply_button = widgets.Button(description=\"Apply and write\", button_style=\"success\")\n",
    "preview_button = widgets.Button(description=\"Preview\", button_style=\"info\")\n",
    "reset_button = widgets.Button(description=\"Reset to default\", button_style=\"warning\")\n",
    "output_area = widgets.Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc47746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collection + Conversion utilities\n",
    "def collect_output_codes_from_ui():\n",
    "    \"\"\"\n",
    "    Collect only filled rows into { code: (label, description) }.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    for k in LEVEL_KEYS:\n",
    "        label = code_widgets[k].value.strip()\n",
    "        desc = desc_widgets[k].value.strip()\n",
    "        if desc:\n",
    "            if not label:\n",
    "                label = f\"D{k}\"\n",
    "            data[k] = (label, desc)\n",
    "    return data\n",
    "\n",
    "def parse_number_or_none(s: str):\n",
    "    t = (s or \"\").strip()\n",
    "    if not t:\n",
    "        return None\n",
    "    if t.lower() == \"none\":\n",
    "        return None\n",
    "    try:\n",
    "        if \".\" in t or \"e\" in t.lower():\n",
    "            return float(t)\n",
    "        return int(t)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def collect_boundaries_from_ui():\n",
    "    \"\"\"\n",
    "    Collect only filled rows into { code: (min, max) }.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    for k in LEVEL_KEYS:\n",
    "        mn = parse_number_or_none(min_widgets[k].value)\n",
    "        mx = parse_number_or_none(max_widgets[k].value)\n",
    "        if mn is not None or mx is not None:\n",
    "            data[k] = (mn, mx)\n",
    "    return data\n",
    "\n",
    "def set_boundaries_enabled(enabled: bool):\n",
    "    for k in LEVEL_KEYS:\n",
    "        min_widgets[k].disabled = not enabled\n",
    "        max_widgets[k].disabled = not enabled\n",
    "\n",
    "def build_modified_init_and_doc_raw(data, plan):\n",
    "    \"\"\"\n",
    "    Return (init_body_raw, doc_block_raw) with *no* leading indentation.\n",
    "    We normalize first, then apply edits, then insert boundaries WITHOUT preserving\n",
    "    any previous indentation. Final indent happens later relative to def_line.\n",
    "    \"\"\"\n",
    "    # Normalize raw init body BEFORE any edits to avoid mixed indent problems\n",
    "    modified_init = textwrap.dedent(data[\"init_body\"].replace(\"\\t\", \"    \")).strip() + \"\\n\"\n",
    "\n",
    "    # Replace/insert input layer\n",
    "    if re.search(r'self\\.input_layer_name\\s*=', modified_init):\n",
    "        modified_init = re.sub(\n",
    "            r'(self\\.input_layer_name\\s*=\\s*)\"[^\"]*\"',\n",
    "            rf'\\1\"{plan[\"new_input\"]}\"',\n",
    "            modified_init,\n",
    "        )\n",
    "    else:\n",
    "        modified_init = f'self.input_layer_name = \"{plan[\"new_input\"]}\"\\n' + modified_init\n",
    "\n",
    "    # Replace/insert output layer\n",
    "    if re.search(r'self\\.output_layer_name\\s*=', modified_init):\n",
    "        modified_init = re.sub(\n",
    "            r'(self\\.output_layer_name\\s*=\\s*)\"[^\"]*\"',\n",
    "            rf'\\1\"{plan[\"new_output\"]}\"',\n",
    "            modified_init,\n",
    "        )\n",
    "    else:\n",
    "        modified_init = f'self.output_layer_name = \"{plan[\"new_output\"]}\"\\n' + modified_init\n",
    "\n",
    "    # Replace/insert layer type\n",
    "    if re.search(r'self\\.layer_type\\s*=', modified_init):\n",
    "        modified_init = re.sub(\n",
    "            r'(self\\.layer_type\\s*=\\s*)[^\\n]+',\n",
    "            rf'\\1{plan[\"new_layer_type\"]}',\n",
    "            modified_init,\n",
    "        )\n",
    "    else:\n",
    "        modified_init += f'\\nself.layer_type = {plan[\"new_layer_type\"]}\\n'\n",
    "\n",
    "    # Output codes\n",
    "    out_dict = collect_output_codes_from_ui()\n",
    "    if out_dict:\n",
    "        pretty_out = format_output_codes_literal(out_dict, indent=\"    \")\n",
    "        if re.search(r'self\\.output_codes_descriptions\\s*=\\s*\\{', modified_init, flags=re.DOTALL):\n",
    "            modified_init = re.sub(\n",
    "                r'(self\\.output_codes_descriptions\\s*=\\s*)\\{.*?\\}',\n",
    "                rf'\\1{pretty_out}',\n",
    "                modified_init,\n",
    "                flags=re.DOTALL,\n",
    "            )\n",
    "        else:\n",
    "            modified_init = f'self.output_codes_descriptions = {pretty_out}\\n' + modified_init\n",
    "\n",
    "    # Boundaries (raw insertion; no indent preservation)\n",
    "    if plan[\"need_boundaries\"]:\n",
    "        bnd_dict = collect_boundaries_from_ui()\n",
    "        pretty_bnd = format_boundaries_literal(bnd_dict, indent=\"    \") if bnd_dict else \"{ }\"\n",
    "        modified_init = remove_existing_boundaries(modified_init)\n",
    "        modified_init = insert_boundaries_after_output_codes(modified_init, pretty_bnd)\n",
    "    else:\n",
    "        modified_init = remove_existing_boundaries(modified_init)\n",
    "\n",
    "    # Docstring (raw)\n",
    "    doctext = docstring_widget.value.strip()\n",
    "    if doctext:\n",
    "        if not (doctext.startswith('\"\"\"') or doctext.startswith(\"'''\")):\n",
    "            doc_block = '\"\"\"\\n' + doctext + '\\n\"\"\"\\n'\n",
    "        else:\n",
    "            doc_block = doctext.strip()\n",
    "            if not doc_block.endswith(\"\\n\"):\n",
    "                doc_block += \"\\n\"\n",
    "    else:\n",
    "        doc_block = (data[\"docstring\"] or \"\").strip()\n",
    "        if doc_block and not doc_block.endswith(\"\\n\"):\n",
    "            doc_block += \"\\n\"\n",
    "\n",
    "    return modified_init, doc_block\n",
    "\n",
    "def compute_conversion_plan(class_name, target_base):\n",
    "    data = classes[class_name]\n",
    "    cur_name = data[\"class_name\"]\n",
    "    cur_input = data[\"input_layer_name\"]\n",
    "    cur_output = data[\"output_layer_name\"]\n",
    "    cur_layer_type = data[\"layer_type\"]\n",
    "\n",
    "    is_to_continuous = \"ContinuousLayer\" in target_base\n",
    "    is_to_categorical = \"CatergoricalLayer\" in target_base or \"CategoricalLayer\" in target_base\n",
    "\n",
    "    new_name = cur_name\n",
    "    new_input = cur_input\n",
    "    new_output = cur_output\n",
    "    new_layer_type = cur_layer_type\n",
    "    need_boundaries = False\n",
    "\n",
    "    if is_to_continuous:\n",
    "        new_name = cur_name.replace(\"L4a\", \"L4d\")\n",
    "        if cur_input:\n",
    "            new_input = cur_input.replace(\"_cat\", \"_con\")\n",
    "        if cur_output:\n",
    "            new_output = cur_output.replace(\"l4a\", \"l4d\").replace(\"_cat\", \"_con\")\n",
    "        new_layer_type = \"l4_base.ClassificationLayerTypes.DERIVATIVE\"\n",
    "        need_boundaries = True\n",
    "    elif is_to_categorical:\n",
    "        new_name = cur_name.replace(\"L4d\", \"L4a\")\n",
    "        if cur_input:\n",
    "            new_input = cur_input.replace(\"_con\", \"_cat\")\n",
    "        if cur_output:\n",
    "            new_output = cur_output.replace(\"l4d\", \"l4a\").replace(\"_con\", \"_cat\")\n",
    "        new_layer_type = \"l4_base.ClassificationLayerTypes.MAIN\"\n",
    "        need_boundaries = False\n",
    "\n",
    "    return {\n",
    "        \"new_class_name\": new_name,\n",
    "        \"new_input\": new_input,\n",
    "        \"new_output\": new_output,\n",
    "        \"new_layer_type\": new_layer_type,\n",
    "        \"need_boundaries\": need_boundaries,\n",
    "    }\n",
    "\n",
    "def remove_existing_boundaries(init_body):\n",
    "    \"\"\"\n",
    "    Remove any existing class_boundaries block from the init body.\n",
    "    \"\"\"\n",
    "    return re.sub(r\"\\n\\s*self\\.class_boundaries\\s*=\\s*\\{.*?\\}\\s*\", \"\\n\", init_body, flags=re.DOTALL)\n",
    "\n",
    "def insert_boundaries_after_output_codes(init_body, boundaries_text):\n",
    "    \"\"\"\n",
    "    Insert boundaries right after the output codes assignment; otherwise append at end.\n",
    "    IMPORTANT: Do NOT preserve legacy indentation here; we insert *raw* lines and\n",
    "    let the final indent step (relative to def_line) make indentation consistent.\n",
    "    \"\"\"\n",
    "    m = re.search(r\"(self\\.output_codes_descriptions\\s*=\\s*\\{.*?\\})\", init_body, flags=re.DOTALL)\n",
    "    if m:\n",
    "        # Insert a raw boundaries line (no leading spaces)\n",
    "        return init_body[: m.end()] + f\"\\nself.class_boundaries = {boundaries_text}\\n\" + init_body[m.end() :]\n",
    "    else:\n",
    "        return init_body + f\"\\nself.class_boundaries = {boundaries_text}\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4017c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI callbacks (load and refresh)\n",
    "def refresh_fields_from_selection(change=None):\n",
    "    selected = class_selector.value\n",
    "    if not selected:\n",
    "        return\n",
    "    data = classes[selected]\n",
    "\n",
    "    # Docstring: show original block as-is\n",
    "    docstring_widget.value = data[\"docstring\"].strip() if data[\"docstring\"] else \"\"\n",
    "\n",
    "    # Reset codes and pre-fill\n",
    "    for k in LEVEL_KEYS:\n",
    "        code_widgets[k].value = \"\"\n",
    "        desc_widgets[k].value = \"\"\n",
    "    if data[\"output_codes_descriptions\"]:\n",
    "        try:\n",
    "            out_dict = ast.literal_eval(data[\"output_codes_descriptions\"])\n",
    "            if isinstance(out_dict, dict):\n",
    "                for k, v in out_dict.items():\n",
    "                    if k in LEVEL_KEYS and isinstance(v, tuple) and len(v) == 2:\n",
    "                        code_widgets[k].value = str(v[0])\n",
    "                        desc_widgets[k].value = str(v[1])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Reset boundaries and pre-fill\n",
    "    for k in LEVEL_KEYS:\n",
    "        min_widgets[k].value = \"\"\n",
    "        max_widgets[k].value = \"\"\n",
    "    if data[\"class_boundaries\"]:\n",
    "        try:\n",
    "            bnd_dict = ast.literal_eval(data[\"class_boundaries\"])\n",
    "            if isinstance(bnd_dict, dict):\n",
    "                for k, v in bnd_dict.items():\n",
    "                    if k in LEVEL_KEYS and isinstance(v, tuple) and len(v) == 2:\n",
    "                        mn, mx = v\n",
    "                        min_widgets[k].value = \"None\" if mn is None else str(mn)\n",
    "                        max_widgets[k].value = \"None\" if mx is None else str(mx)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Sync base selector to current base\n",
    "    if data[\"base_class\"] in base_selector.options:\n",
    "        base_selector.value = data[\"base_class\"]\n",
    "    else:\n",
    "        opts = list(base_selector.options)\n",
    "        if data[\"base_class\"] not in opts:\n",
    "            opts.append(data[\"base_class\"])\n",
    "        base_selector.options = opts\n",
    "        base_selector.value = data[\"base_class\"]\n",
    "\n",
    "    plan = compute_conversion_plan(selected, base_selector.value)\n",
    "    set_boundaries_enabled(plan[\"need_boundaries\"])\n",
    "\n",
    "def on_base_selector_change(change):\n",
    "    selected = class_selector.value\n",
    "    if not selected:\n",
    "        return\n",
    "    plan = compute_conversion_plan(selected, base_selector.value)\n",
    "    set_boundaries_enabled(plan[\"need_boundaries\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06b9206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview and apply\n",
    "def on_preview_clicked(b):\n",
    "    \"\"\"\n",
    "    Build the new class block, format with Black using a scaffold, show preview.\n",
    "    \"\"\"\n",
    "    selected = class_selector.value\n",
    "    if not selected:\n",
    "        return\n",
    "    data = classes[selected]\n",
    "    plan = compute_conversion_plan(selected, base_selector.value)\n",
    "\n",
    "    init_raw, doc_raw = build_modified_init_and_doc_raw(data, plan)\n",
    "\n",
    "    # Detect class inner indent from the original class block when possible\n",
    "    class_inner_ws = detect_class_inner_indent(data[\"full_block\"])\n",
    "    def_line = f\"{class_inner_ws}def __init__(self):\\n\"\n",
    "\n",
    "    # Black-format the class fragment via scaffold\n",
    "    try:\n",
    "        pretty = black_format_block_with_scaffold(\n",
    "            class_name=plan[\"new_class_name\"],\n",
    "            base=base_selector.value,\n",
    "            doc_raw=doc_raw,\n",
    "            def_line=def_line,\n",
    "            body_raw=init_raw,\n",
    "            class_inner_ws=class_inner_ws,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        # Fall back to raw view (still indented relatively) if Black fails\n",
    "        doc_indented = textwrap.indent(textwrap.dedent(doc_raw).strip() + \"\\n\", class_inner_ws)\n",
    "        body_indented = indent_one_level(init_raw, def_line)\n",
    "        pretty = (\n",
    "            f\"Black formatting failed: {e}\\n\\n\"\n",
    "            f\"class {plan['new_class_name']}({base_selector.value}):\\n\"\n",
    "            + doc_indented\n",
    "            + def_line\n",
    "            + body_indented\n",
    "        )\n",
    "\n",
    "    with output_area:\n",
    "        output_area.clear_output(wait=True)\n",
    "        print(\"----- PREVIEW -----\\n\")\n",
    "        print(pretty)\n",
    "        print(\"\\n-------------------\")\n",
    "\n",
    "\n",
    "def on_apply_clicked(b):\n",
    "    \"\"\"\n",
    "    Build the new class block, splice it into working_text, format entire file,\n",
    "    write to OUTPUT, then refresh classes and dropdown.\n",
    "    \"\"\"\n",
    "    global working_text, classes\n",
    "\n",
    "    selected = class_selector.value\n",
    "    if not selected:\n",
    "        return\n",
    "    data = classes[selected]\n",
    "    plan = compute_conversion_plan(selected, base_selector.value)\n",
    "\n",
    "    if not modification_log:\n",
    "        shutil.copyfile(SOURCE, SOURCE + \".bak\")\n",
    "\n",
    "    init_raw, doc_raw = build_modified_init_and_doc_raw(data, plan)\n",
    "    class_inner_ws = detect_class_inner_indent(data[\"full_block\"])\n",
    "    def_line = f\"{class_inner_ws}def __init__(self):\\n\"\n",
    "\n",
    "    # Format the new class block first (clean injection), then splice\n",
    "    clean_block = black_format_block_with_scaffold(\n",
    "        class_name=plan[\"new_class_name\"],\n",
    "        base=base_selector.value,\n",
    "        doc_raw=doc_raw,\n",
    "        def_line=def_line,\n",
    "        body_raw=init_raw,\n",
    "        class_inner_ws=class_inner_ws,\n",
    "    )\n",
    "\n",
    "    start, end = data[\"match_span\"]\n",
    "    working_text = working_text[:start] + clean_block + working_text[end:]\n",
    "\n",
    "    # Validate entire file, then format with Black\n",
    "    try:\n",
    "        ast.parse(working_text)\n",
    "    except SyntaxError as e:\n",
    "        with output_area:\n",
    "            output_area.clear_output(wait=True)\n",
    "            print(f\"SyntaxError in generated file: {e}\")\n",
    "        return\n",
    "\n",
    "    formatted_text = format_with_black(working_text)\n",
    "    with open(OUTPUT, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(formatted_text)\n",
    "\n",
    "    # Rebuild metadata from the formatted text, update dropdown\n",
    "    classes = build_classes_from_text(formatted_text)\n",
    "    class_selector.options = sorted(list(classes.keys()))\n",
    "\n",
    "    modification_log.append(f\"Modifications for '{selected}' saved in {OUTPUT}\")\n",
    "    with output_area:\n",
    "        output_area.clear_output(wait=True)\n",
    "        for msg in modification_log:\n",
    "            print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640b3546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI wire and display\n",
    "def on_class_change(ch):\n",
    "    \"\"\"\n",
    "    Rebuild classes from current working_text, update dropdown, refresh widgets.\n",
    "    \"\"\"\n",
    "    global classes\n",
    "    classes = build_classes_from_text(working_text)\n",
    "    class_selector.options = sorted(list(classes.keys()))\n",
    "    refresh_fields_from_selection(ch)\n",
    "\n",
    "class_selector.observe(on_class_change, names=\"value\")\n",
    "base_selector.observe(on_base_selector_change, names=\"value\")\n",
    "apply_button.on_click(on_apply_clicked)\n",
    "preview_button.on_click(on_preview_clicked)\n",
    "\n",
    "def on_reset_clicked(b):\n",
    "    \"\"\"\n",
    "    Reset to ORIGINAL source: reload, rebuild classes, update dropdown, refresh UI.\n",
    "    \"\"\"\n",
    "    global working_text, classes\n",
    "    with open(SOURCE, \"r\", encoding=\"utf-8\") as f:\n",
    "        source_text_fresh = f.read()\n",
    "    working_text = source_text_fresh\n",
    "    classes = build_classes_from_text(source_text_fresh)\n",
    "    class_selector.options = sorted(list(classes.keys()))\n",
    "    refresh_fields_from_selection()\n",
    "\n",
    "reset_button.on_click(on_reset_clicked)\n",
    "\n",
    "# Initial fill\n",
    "if class_selector.value:\n",
    "    refresh_fields_from_selection()\n",
    "\n",
    "controls = widgets.VBox(\n",
    "    [\n",
    "        widgets.HBox([class_selector, base_selector]),\n",
    "        docstring_widget,\n",
    "        advanced_box,  # per-level editors\n",
    "        widgets.HBox([preview_button, apply_button, reset_button]),\n",
    "        output_area,\n",
    "    ]\n",
    ")\n",
    "\n",
    "display(controls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "le4ld",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
